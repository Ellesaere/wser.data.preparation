merged_df <- merge(merged_df, consortium2, by = "ubn", all.x = TRUE, suffixes = c("", "_LBV_KS"), allow.cartesian = TRUE)
merged_df <- merge(merged_df, claim_df,    by = "ubn", all.x = TRUE, suffixes = c("", "_claim"), allow.cartesian = TRUE)
# 6. Check for duplicate combinations of brs and gojaar
cat("Duplicates in ubn ID + gojaar (after merge):\n")
print(merged_df[duplicated(merged_df[, .(ubn, year)]), unique(ubn)])
# 7. Check for duplicate column names
# Example: check for columns created due to suffix "_c1"
dup_c1 <- grep("_LBV$", names(merged_df), value = TRUE)
dup_c2 <- grep("_LBV_KS$", names(merged_df), value = TRUE) # DOUBLE APPLICATION?
dup_claim <- grep("_claim$", names(merged_df), value = TRUE)
cat("Columns created due to _c1 suffix:\n")
print(dup_c1)
cat("Columns created due to _c2 suffix:\n")
print(dup_c2)
cat("Columns created due to _claim suffix:\n")
print(dup_claim)
View(emission_list)
View(overview)
# Explanation of options:
# | Option           | What it does                                   |
# |------------------|------------------------------------------------|
# | `echo=FALSE`     | Hides the **code** but shows the **output**    |
# | `message=FALSE`  | Suppresses messages (e.g., package messages)   |
# | `warning=FALSE`  | Suppresses warnings                            |
# | `include=FALSE`  | Runs code but shows **neither code nor output**|
# | `results='hide'` | Hides printed output, but shows plots          |
################################################################################
### 1. Options #################################################################
################################################################################
oldw <- getOption("warn")
options(scipen=999)
################################################################################
### 2. Libraries ###############################################################
################################################################################
devtools::install_github("Ellesaere/wser.data.preparation")
library(wser.data.preparation)
packages <- c(
"data.table",
"sf",
"terra"
)
# Install packages that are not yet installed
# https://stackoverflow.com/questions/9341635/check-for-installed-packages-before-running-install-packages
install.packages(setdiff(packages, rownames(installed.packages())))
# Load libraries
options(warn = -1)
x <- lapply(packages, function(packages) {if (!require(packages, character.only = TRUE, quietly = TRUE, warn.conflicts=FALSE)) {library(packages, character.only = T, quietly = TRUE, warn.conflicts=FALSE)}})
options(warn = oldw)
################################################################################
### 3. Data ####################################################################
################################################################################
path <- "W:\\PROJECTS\\MESN-WSER_2025\\InitialData\\"
# data_list <- read_files_from_path(path, extensions = c("xlsx"), add_all_tabs = TRUE, clean = TRUE)
# saveRDS(data_list, file = "W:/PROJECTS/MESN-WSER_2025/Data/data_list.rds")
# These simply loads all Excel files (and their tabs in a list)
data_list <- readRDS("W:/PROJECTS/MESN-WSER_2025/Data/data_list.rds")
# This loads all emission files
emissions_path <- "W:\\PROJECTS\\MESN-WSER_2025\\InitialData\\INITIATOR_emissies"
emission_list <- read_files_from_path(emissions_path, extensions = c("csv"), add_all_tabs = TRUE, clean = TRUE)
################################################################################
### 4. Select actual data ######################################################
################################################################################
# 4.1 Only keep tabs with more than 100 rows (the actual data) #################
filter_large_datasets <- function(data_list) {
data_list[sapply(data_list, function(x) is.data.frame(x) && nrow(x) > 100)]
}
filtered_data_list <- filter_large_datasets(data_list)
# 4.2 Look for connecting variables (BRS and year) #############################
find_columns_with_brs_or_jaar <- function(data_list) {
result <- lapply(names(data_list), function(name) {
df <- data_list[[name]]
if (!is.data.frame(df)) return(NULL)
cols <- colnames(df)
matches_brs <- grepl("brs", cols, ignore.case = TRUE)
matches_jaar <- grepl("jaar", cols, ignore.case = TRUE)
if (any(matches_brs | matches_jaar)) {
return(data.frame(
dataset = name,
brs_columns = paste(cols[matches_brs], collapse = ", "),
jaar_columns = paste(cols[matches_jaar], collapse = ", "),
stringsAsFactors = FALSE
))
} else {
return(NULL)
}
})
do.call(rbind, Filter(Negate(is.null), result))
}
overview <- find_columns_with_brs_or_jaar(filtered_data_list)
print(overview)
################################################################################
### 5. Rowbind data with columns brsir AND gojaar ##############################
################################################################################
# This dataset is a bit different from the others
data_to_skip_and_add_at_the_end <- c("OHV19check18v3_OHV19check18")
# Define prefixes to skip digit removal
variables_from_which_nrs_should_not_be_removed <- c("natec")
# Step 1: Filter matched datasets, excluding the deferred ones
matched_dfs <- Filter(Negate(is.null), lapply(names(filtered_data_list), function(name) {
if (name %in% data_to_skip_and_add_at_the_end) return(NULL)
df <- as.data.table(filtered_data_list[[name]])
colnames_lower <- tolower(names(df))
if ("brsir" %in% colnames_lower && "gojaar" %in% colnames_lower && grepl("check", name, ignore.case = TRUE)) {
return(df)
}
NULL
}))
# Step 2: Normalize function
normalize_name <- function(x) {
if (any(startsWith(tolower(x), tolower(variables_from_which_nrs_should_not_be_removed)))) {
x
} else {
gsub("[0-9]", "", x)
}
}
# Step 3: Normalize column names in matched data
matched_dfs <- lapply(matched_dfs, function(df) {
setnames(df, old = names(df), new = sapply(names(df), normalize_name))
return(df)
})
# Step 4: Get common columns
common_cols <- Reduce(intersect, lapply(matched_dfs, names))
# Step 5: Subset and rowbind matched dfs
combined_df <- rbindlist(lapply(matched_dfs, function(df) df[, ..common_cols]), use.names = TRUE, fill = TRUE)
# Step 6: Handle deferred datasets (e.g., OHV19check18v3_OHV19check18)
for (name in data_to_skip_and_add_at_the_end) {
df_extra <- as.data.table(filtered_data_list[[name]])
setnames(df_extra, old = names(df_extra), new = sapply(names(df_extra), normalize_name))
# Keep only common cols (add NA for missing ones)
missing_cols <- setdiff(common_cols, names(df_extra))
for (col in missing_cols) df_extra[[col]] <- NA
df_extra <- df_extra[, ..common_cols]
combined_df <- rbindlist(list(combined_df, df_extra), use.names = TRUE, fill = TRUE)
}
# Ensure final output is a data.table
combined_df <- as.data.table(combined_df)
# Optional: Check column names
dput(names(combined_df))
names_combined_df <- c("relatienr", "ubn", "aanvraagnr", "diersoort", "volgnr", "ingebrjr",
"natec1", "natec1oms", "natec2", "natec2oms", "natec3", "natec3oms",
"diercat", "diercatoms", "soorthuisv", "soorthuisvoms", "staltype",
"staltypeoms", "melkvee", "jongvee", "waterbuffels", "brsir",
"xco", "yco", "gojaar", "asbseldatum", "ravcode", "ravomschrijving",
"splits", "diergroep", "diergroeplang", "Bron", "FracRose", "dieren",
"Lbt", "gemir", "dierkeuze", "BtypNL")
# ALL OBSERVATIONS WITHOUT UBN REMOVED
# https://www.rvo.nl/onderwerpen/identificatie-en-registratie-dieren/dierlocatie-ubn
combined_df_filtered_out <- combined_df[is.na(ubn) | ubn == 0]
combined_df <- combined_df[!is.na(ubn) & ubn != 0]
table(combined_df_filtered_out$diersoort)
# This is a check to see which animas are filtered out of the main data
table(combined_df_filtered_out$diersoort)
################################################################################
### 6. Merge all data without columns brsir and gojaar #########################
################################################################################
brs_only_list <- list(
A_and_R_LBV_CONSORTIUM = filtered_data_list[["A_and_R_LBV_CONSORTIUM_20250507_LBV_CONSORTIUM_NIEUW_6"]],
A_and_R_LBV_KS_CONSORTIUM = filtered_data_list[["A_and_R_LBV_KS_CONSORTIUM_20250507_CONSORTIUM_LBV_KS_3_3"]],
SAS_SRVH_Berekening_Claim = filtered_data_list[["SAS_SRVH_Berekening_Claim_mesn_SRVH_BEREKENING_CLAIM_2025"]]
)
# 1. Standardize combined_df ID column
setnames(combined_df, old = "relatienr", new = "brs", skip_absent = TRUE)
setnames(combined_df, old = "gojaar", new = "year", skip_absent = TRUE)
combined_df[, brs := as.character(brs)]
combined_df[, ubn := as.character(ubn)]
# 2. Merge in A_and_R_LBV_CONSORTIUM
consortium1 <- as.data.table(brs_only_list[["A_and_R_LBV_CONSORTIUM"]])
setnames(consortium1, old = "BRS_REL_NR_AANVRAGER", new = "brs", skip_absent = TRUE)
setnames(consortium1, old = "UBN_NR", new = "ubn", skip_absent = TRUE)
consortium1[, brs := as.character(brs)]
consortium1[, ubn := as.character(ubn)]
# 3. Merge in A_and_R_LBV_KS_CONSORTIUM
consortium2 <- as.data.table(brs_only_list[["A_and_R_LBV_KS_CONSORTIUM"]])
setnames(consortium2, old = "BRS_REL_NR_AANVRAGER", new = "brs", skip_absent = TRUE)
setnames(consortium2, old = "UBN_NR", new = "ubn", skip_absent = TRUE)
consortium2[, brs := as.character(brs)]
consortium2[, ubn := as.character(ubn)]
# 4. Merge in SAS_SRVH_Berekening_Claim
claim_df <- as.data.table(brs_only_list[["SAS_SRVH_Berekening_Claim"]])
setnames(claim_df, old = "BRS nummer", new = "brs", skip_absent = TRUE)
setnames(claim_df, old = "UBN nummer", new = "ubn", skip_absent = TRUE)
claim_df[, brs := as.character(brs)]
claim_df[, ubn := as.character(ubn)]
# Optional: check duplicates BEFORE merging
cat("Duplicates in ubn IDs (before merge):\n")
print(combined_df[duplicated(ubn), unique(ubn)])
# 5. Merge step-by-step, checking for duplicate columns
merged_df <- merge(combined_df, consortium1, by = "ubn", all.x = TRUE, suffixes = c("", "_LBV"), allow.cartesian = TRUE)
merged_df <- merge(merged_df, consortium2, by = "ubn", all.x = TRUE, suffixes = c("", "_LBV_KS"), allow.cartesian = TRUE)
merged_df <- merge(merged_df, claim_df,    by = "ubn", all.x = TRUE, suffixes = c("", "_claim"), allow.cartesian = TRUE)
# 6. Check for duplicate combinations of brs and gojaar
cat("Duplicates in ubn ID + gojaar (after merge):\n")
print(merged_df[duplicated(merged_df[, .(ubn, year)]), unique(ubn)])
# 7. Check for duplicate column names
# Example: check for columns created due to suffix "_c1"
dup_c1 <- grep("_LBV$", names(merged_df), value = TRUE)
dup_c2 <- grep("_LBV_KS$", names(merged_df), value = TRUE) # DOUBLE APPLICATION?
dup_claim <- grep("_claim$", names(merged_df), value = TRUE)
View(combined_df)
str(combined_df)
empty_df <- merged_df_clean_geo[0, ]
empty_df <- combined_df[0, ]
str(empty_df)  # Now this prints structure without data
################################################################################
### 5. Rowbind data with columns brsir AND gojaar ##############################
################################################################################
# This dataset is a bit different from the others
data_to_skip_and_add_at_the_end <- c("OHV19check18v3_OHV19check18")
# Define prefixes to skip digit removal
variables_from_which_nrs_should_not_be_removed <- c("natec")
# Step 1: Filter matched datasets, excluding the deferred ones
matched_dfs <- Filter(Negate(is.null), lapply(names(filtered_data_list), function(name) {
if (name %in% data_to_skip_and_add_at_the_end) return(NULL)
df <- as.data.table(filtered_data_list[[name]])
colnames_lower <- tolower(names(df))
if ("brsir" %in% colnames_lower && "gojaar" %in% colnames_lower && grepl("check", name, ignore.case = TRUE)) {
return(df)
}
NULL
}))
# Step 2: Normalize function
normalize_name <- function(x) {
if (any(startsWith(tolower(x), tolower(variables_from_which_nrs_should_not_be_removed)))) {
x
} else {
gsub("[0-9]", "", x)
}
}
# Step 3: Normalize column names in matched data
matched_dfs <- lapply(matched_dfs, function(df) {
setnames(df, old = names(df), new = sapply(names(df), normalize_name))
return(df)
})
# Step 4: Get common columns
common_cols <- Reduce(intersect, lapply(matched_dfs, names))
# Step 5: Subset and rowbind matched dfs
combined_df <- rbindlist(lapply(matched_dfs, function(df) df[, ..common_cols]), use.names = TRUE, fill = TRUE)
# Step 6: Handle deferred datasets (e.g., OHV19check18v3_OHV19check18)
for (name in data_to_skip_and_add_at_the_end) {
df_extra <- as.data.table(filtered_data_list[[name]])
setnames(df_extra, old = names(df_extra), new = sapply(names(df_extra), normalize_name))
# Keep only common cols (add NA for missing ones)
missing_cols <- setdiff(common_cols, names(df_extra))
for (col in missing_cols) df_extra[[col]] <- NA
df_extra <- df_extra[, ..common_cols]
combined_df <- rbindlist(list(combined_df, df_extra), use.names = TRUE, fill = TRUE)
}
# Ensure final output is a data.table
combined_df <- as.data.table(combined_df)
# Optional: Check column names
dput(names(combined_df))
names_combined_df <- c("relatienr", "ubn", "aanvraagnr", "diersoort", "volgnr", "ingebrjr",
"natec1", "natec1oms", "natec2", "natec2oms", "natec3", "natec3oms",
"diercat", "diercatoms", "soorthuisv", "soorthuisvoms", "staltype",
"staltypeoms", "melkvee", "jongvee", "waterbuffels", "brsir",
"xco", "yco", "gojaar", "asbseldatum", "ravcode", "ravomschrijving",
"splits", "diergroep", "diergroeplang", "Bron", "FracRose", "dieren",
"Lbt", "gemir", "dierkeuze", "BtypNL")
empty_df <- merged_df_clean_geo[0, ]
################################################################################
### 5. Rowbind data with columns brsir AND gojaar ##############################
################################################################################
# This dataset is a bit different from the others
data_to_skip_and_add_at_the_end <- c("OHV19check18v3_OHV19check18")
# Define prefixes to skip digit removal
variables_from_which_nrs_should_not_be_removed <- c("natec")
# Step 1: Filter matched datasets, excluding the deferred ones
matched_dfs <- Filter(Negate(is.null), lapply(names(filtered_data_list), function(name) {
if (name %in% data_to_skip_and_add_at_the_end) return(NULL)
df <- as.data.table(filtered_data_list[[name]])
colnames_lower <- tolower(names(df))
if ("brsir" %in% colnames_lower && "gojaar" %in% colnames_lower && grepl("check", name, ignore.case = TRUE)) {
return(df)
}
NULL
}))
# Step 2: Normalize function
normalize_name <- function(x) {
if (any(startsWith(tolower(x), tolower(variables_from_which_nrs_should_not_be_removed)))) {
x
} else {
gsub("[0-9]", "", x)
}
}
# Step 3: Normalize column names in matched data
matched_dfs <- lapply(matched_dfs, function(df) {
setnames(df, old = names(df), new = sapply(names(df), normalize_name))
return(df)
})
# Step 4: Get common columns
common_cols <- Reduce(intersect, lapply(matched_dfs, names))
# Step 5: Subset and rowbind matched dfs
combined_df <- rbindlist(lapply(matched_dfs, function(df) df[, ..common_cols]), use.names = TRUE, fill = TRUE)
# Step 6: Handle deferred datasets (e.g., OHV19check18v3_OHV19check18)
for (name in data_to_skip_and_add_at_the_end) {
df_extra <- as.data.table(filtered_data_list[[name]])
setnames(df_extra, old = names(df_extra), new = sapply(names(df_extra), normalize_name))
# Keep only common cols (add NA for missing ones)
missing_cols <- setdiff(common_cols, names(df_extra))
for (col in missing_cols) df_extra[[col]] <- NA
df_extra <- df_extra[, ..common_cols]
combined_df <- rbindlist(list(combined_df, df_extra), use.names = TRUE, fill = TRUE)
}
# Ensure final output is a data.table
combined_df <- as.data.table(combined_df)
# Optional: Check column names
dput(names(combined_df))
names_combined_df <- c("relatienr", "ubn", "aanvraagnr", "diersoort", "volgnr", "ingebrjr",
"natec1", "natec1oms", "natec2", "natec2oms", "natec3", "natec3oms",
"diercat", "diercatoms", "soorthuisv", "soorthuisvoms", "staltype",
"staltypeoms", "melkvee", "jongvee", "waterbuffels", "brsir",
"xco", "yco", "gojaar", "asbseldatum", "ravcode", "ravomschrijving",
"splits", "diergroep", "diergroeplang", "Bron", "FracRose", "dieren",
"Lbt", "gemir", "dierkeuze", "BtypNL")
empty_df <- combined_df[0, ]
print(str(empty_df))  # Now this prints structure without data
################################################################################
### 5. Rowbind data with columns brsir AND gojaar ##############################
################################################################################
# This dataset is a bit different from the others
data_to_skip_and_add_at_the_end <- c("OHV19check18v3_OHV19check18")
# Define prefixes to skip digit removal
variables_from_which_nrs_should_not_be_removed <- c("natec")
# Step 1: Filter matched datasets, excluding the deferred ones
matched_dfs <- Filter(Negate(is.null), lapply(names(filtered_data_list), function(name) {
if (name %in% data_to_skip_and_add_at_the_end) return(NULL)
df <- as.data.table(filtered_data_list[[name]])
colnames_lower <- tolower(names(df))
if ("brsir" %in% colnames_lower && "gojaar" %in% colnames_lower && grepl("check", name, ignore.case = TRUE)) {
return(df)
}
NULL
}))
# Step 2: Normalize function
normalize_name <- function(x) {
if (any(startsWith(tolower(x), tolower(variables_from_which_nrs_should_not_be_removed)))) {
x
} else {
gsub("[0-9]", "", x)
}
}
# Step 3: Normalize column names in matched data
matched_dfs <- lapply(matched_dfs, function(df) {
setnames(df, old = names(df), new = sapply(names(df), normalize_name))
return(df)
})
# Step 4: Get common columns
common_cols <- Reduce(intersect, lapply(matched_dfs, names))
# Step 5: Subset and rowbind matched dfs
combined_df <- rbindlist(lapply(matched_dfs, function(df) df[, ..common_cols]), use.names = TRUE, fill = TRUE)
# Step 6: Handle deferred datasets (e.g., OHV19check18v3_OHV19check18)
for (name in data_to_skip_and_add_at_the_end) {
df_extra <- as.data.table(filtered_data_list[[name]])
setnames(df_extra, old = names(df_extra), new = sapply(names(df_extra), normalize_name))
# Keep only common cols (add NA for missing ones)
missing_cols <- setdiff(common_cols, names(df_extra))
for (col in missing_cols) df_extra[[col]] <- NA
df_extra <- df_extra[, ..common_cols]
combined_df <- rbindlist(list(combined_df, df_extra), use.names = TRUE, fill = TRUE)
}
# Ensure final output is a data.table
combined_df <- as.data.table(combined_df)
# Optional: Check column names
# dput(names(combined_df))
names_combined_df <- c("relatienr", "ubn", "aanvraagnr", "diersoort", "volgnr", "ingebrjr", "natec1", "natec1oms", "natec2", "natec2oms", "natec3", "natec3oms",
"diercat", "diercatoms", "soorthuisv", "soorthuisvoms", "staltype",
"staltypeoms", "melkvee", "jongvee", "waterbuffels", "brsir",
"xco", "yco", "gojaar", "asbseldatum", "ravcode", "ravomschrijving",
"splits", "diergroep", "diergroeplang", "Bron", "FracRose", "dieren",
"Lbt", "gemir", "dierkeuze", "BtypNL")
empty_df <- combined_df[0, ]
print(str(empty_df))  # Now this prints structure without data
print(str(empty_df))  # Now this prints structure without data
# ALL OBSERVATIONS WITHOUT UBN REMOVED
# https://www.rvo.nl/onderwerpen/identificatie-en-registratie-dieren/dierlocatie-ubn
combined_df_filtered_out <- combined_df[is.na(ubn) | ubn == 0]
combined_df <- combined_df[!is.na(ubn) & ubn != 0]
table(combined_df_filtered_out$diersoort)
# This is a check to see which animas are filtered out of the main data
################################################################################
### 6. Merge all data without columns brsir and gojaar #########################
################################################################################
brs_only_list <- list(
A_and_R_LBV_CONSORTIUM = filtered_data_list[["A_and_R_LBV_CONSORTIUM_20250507_LBV_CONSORTIUM_NIEUW_6"]],
A_and_R_LBV_KS_CONSORTIUM = filtered_data_list[["A_and_R_LBV_KS_CONSORTIUM_20250507_CONSORTIUM_LBV_KS_3_3"]],
SAS_SRVH_Berekening_Claim = filtered_data_list[["SAS_SRVH_Berekening_Claim_mesn_SRVH_BEREKENING_CLAIM_2025"]]
)
# 1. Standardize combined_df ID column
setnames(combined_df, old = "relatienr", new = "brs", skip_absent = TRUE)
setnames(combined_df, old = "gojaar", new = "year", skip_absent = TRUE)
combined_df[, brs := as.character(brs)]
combined_df[, ubn := as.character(ubn)]
# 2. Merge in A_and_R_LBV_CONSORTIUM
consortium1 <- as.data.table(brs_only_list[["A_and_R_LBV_CONSORTIUM"]])
setnames(consortium1, old = "BRS_REL_NR_AANVRAGER", new = "brs", skip_absent = TRUE)
setnames(consortium1, old = "UBN_NR", new = "ubn", skip_absent = TRUE)
consortium1[, brs := as.character(brs)]
consortium1[, ubn := as.character(ubn)]
# 3. Merge in A_and_R_LBV_KS_CONSORTIUM
consortium2 <- as.data.table(brs_only_list[["A_and_R_LBV_KS_CONSORTIUM"]])
setnames(consortium2, old = "BRS_REL_NR_AANVRAGER", new = "brs", skip_absent = TRUE)
setnames(consortium2, old = "UBN_NR", new = "ubn", skip_absent = TRUE)
consortium2[, brs := as.character(brs)]
consortium2[, ubn := as.character(ubn)]
# 4. Merge in SAS_SRVH_Berekening_Claim
claim_df <- as.data.table(brs_only_list[["SAS_SRVH_Berekening_Claim"]])
setnames(claim_df, old = "BRS nummer", new = "brs", skip_absent = TRUE)
setnames(claim_df, old = "UBN nummer", new = "ubn", skip_absent = TRUE)
claim_df[, brs := as.character(brs)]
claim_df[, ubn := as.character(ubn)]
# Optional: check duplicates BEFORE merging
cat("Duplicates in ubn IDs (before merge):\n")
print(combined_df[duplicated(ubn), unique(ubn)])
# 5. Merge step-by-step, checking for duplicate columns
merged_df <- merge(combined_df, consortium1, by = "ubn", all.x = TRUE, suffixes = c("", "_LBV"), allow.cartesian = TRUE)
merged_df <- merge(merged_df, consortium2, by = "ubn", all.x = TRUE, suffixes = c("", "_LBV_KS"), allow.cartesian = TRUE)
merged_df <- merge(merged_df, claim_df,    by = "ubn", all.x = TRUE, suffixes = c("", "_claim"), allow.cartesian = TRUE)
# 6. Check for duplicate combinations of brs and gojaar
cat("Duplicates in ubn ID + gojaar (after merge):\n")
print(merged_df[duplicated(merged_df[, .(ubn, year)]), unique(ubn)])
# 7. Check for duplicate column names
# Example: check for columns created due to suffix "_c1"
dup_c1 <- grep("_LBV$", names(merged_df), value = TRUE)
dup_c2 <- grep("_LBV_KS$", names(merged_df), value = TRUE) # DOUBLE APPLICATION?
dup_claim <- grep("_claim$", names(merged_df), value = TRUE)
wser.data.preparation::create_dummy_data()
wser.data.preparation::create_dummy_data
################################################################################
### 1. Options #################################################################
################################################################################
oldw <- getOption("warn")
options(scipen=999)
################################################################################
### 2. Libraries ###############################################################
################################################################################
devtools::install_github("Ellesaere/wser.data.preparation")
library(wser.data.preparation)
packages <- c(
"data.table",
"sf",
"terra"
)
# Install packages that are not yet installed
# https://stackoverflow.com/questions/9341635/check-for-installed-packages-before-running-install-packages
install.packages(setdiff(packages, rownames(installed.packages())))
# Load libraries
options(warn = -1)
x <- lapply(packages, function(packages) {if (!require(packages, character.only = TRUE, quietly = TRUE, warn.conflicts=FALSE)) {library(packages, character.only = T, quietly = TRUE, warn.conflicts=FALSE)}})
options(warn = oldw)
add_noise_to_data <- function(data, percent = 1, exclude_cols = NULL, copy_data = TRUE) {
if (!inherits(data, "data.table")) {
data <- as.data.table(data)
}
if (copy_data) {
data <- copy(data)  # avoid modifying original in-place
}
for (col_name in names(data)) {
if (col_name %in% exclude_cols) next
col_data <- data[[col_name]]
if (is.numeric(col_data)) {
noise <- sapply(col_data, function(x) {
if (is.na(x) || x == 0) return(0)
range <- abs(x) * (percent / 100)
runif(1, -range, range)
})
data[[col_name]] <- col_data + noise
}
}
return(data)
}
################################################################################
### 3. Data ####################################################################
################################################################################
path <- "W:\\PROJECTS\\MESN-WSER_2025\\InitialData\\"
# data_list <- read_files_from_path(path, extensions = c("xlsx"), add_all_tabs = TRUE, clean = TRUE)
# saveRDS(data_list, file = "W:/PROJECTS/MESN-WSER_2025/Data/data_list.rds")
# These simply loads all Excel files (and their tabs in a list)
data_list <- readRDS("W:/PROJECTS/MESN-WSER_2025/Data/data_list.rds")
# This loads all emission files
emissions_path <- "W:\\PROJECTS\\MESN-WSER_2025\\InitialData\\INITIATOR_emissies"
emission_list <- read_files_from_path(emissions_path, extensions = c("csv"), add_all_tabs = TRUE, clean = TRUE)
################################################################################
### 4. Select actual data ######################################################
################################################################################
# 4.1 Only keep tabs with more than 100 rows (the actual data) #################
filter_large_datasets <- function(data_list) {
data_list[sapply(data_list, function(x) is.data.frame(x) && nrow(x) > 100)]
}
filtered_data_list <- filter_large_datasets(data_list)
# 4.2 Look for connecting variables (BRS and year) #############################
find_columns_with_brs_or_jaar <- function(data_list) {
result <- lapply(names(data_list), function(name) {
df <- data_list[[name]]
if (!is.data.frame(df)) return(NULL)
cols <- colnames(df)
matches_brs <- grepl("brs", cols, ignore.case = TRUE)
matches_jaar <- grepl("jaar", cols, ignore.case = TRUE)
if (any(matches_brs | matches_jaar)) {
return(data.frame(
dataset = name,
brs_columns = paste(cols[matches_brs], collapse = ", "),
jaar_columns = paste(cols[matches_jaar], collapse = ", "),
stringsAsFactors = FALSE
))
} else {
return(NULL)
}
})
do.call(rbind, Filter(Negate(is.null), result))
}
overview <- find_columns_with_brs_or_jaar(filtered_data_list)
View(combined_df)
